{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import json\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import documents\n",
    "main_doc = 'intents.json'\n",
    "text_doc = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(main_doc,) as f:\n",
    "    data = json.load(f)\n",
    "    for Dept in data['Economics']:\n",
    "        course = Dept['Course']\n",
    "        question = Dept['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 2\n",
      "[['the', 'branch', 'of', 'economics', 'concerned', 'with', 'the', 'use', 'of', 'mathematical', 'methods', '(', 'especially', 'statistics', ')', 'in', 'describing', 'economic', 'systems', '.'], ['econometrics', 'sutudies', 'how', 'mathematics', 'relates', 'with', 'economics']] \n",
      "\n",
      "[['(', 0.21], [')', 0.21], ['.', 0.21], ['branch', 0.21], ['concerned', 0.21], ['describing', 0.21], ['economic', 0.21], ['especially', 0.21], ['in', 0.21], ['mathematical', 0.21], ['methods', 0.21], ['of', 0.43], ['statistics', 0.21], ['systems', 0.21], ['the', 0.43], ['use', 0.21]]\n",
      "[['econometrics', 0.45], ['how', 0.45], ['mathematics', 0.45], ['relates', 0.45], ['sutudies', 0.45]]\n"
     ]
    }
   ],
   "source": [
    "file_docs = []\n",
    "\n",
    "#load document and make sentence tokens\n",
    "\n",
    "with open(main_doc,) as f:\n",
    "    data = json.load(f)\n",
    "    for Dept in data['Economics']:\n",
    "        course = Dept['Course']\n",
    "        question = Dept['question']\n",
    "        for answers in Dept['answers']:\n",
    "            tokens = sent_tokenize(answers)\n",
    "            for line in tokens:\n",
    "                file_docs.append(line)\n",
    "        print(\"Number of sentences:\",len(file_docs))\n",
    "        #make sentence into word tokens\n",
    "        gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "                    for text in file_docs]\n",
    "        print(gen_docs, \"\\n\")\n",
    "#Check how tokenized words occur in the sentence and make weighted summary. \n",
    "#Words will least occurence get high weights, while words with high occurence get low weights or disappear altogether\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "for doc in tf_idf[corpus]:\n",
    "    print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(': 0, ')': 1, '.': 2, 'branch': 3, 'concerned': 4, 'describing': 5, 'economic': 6, 'economics': 7, 'especially': 8, 'in': 9, 'mathematical': 10, 'methods': 11, 'of': 12, 'statistics': 13, 'systems': 14, 'the': 15, 'use': 16, 'with': 17, 'econometrics': 18, 'how': 19, 'mathematics': 20, 'relates': 21, 'sutudies': 22}\n"
     ]
    }
   ],
   "source": [
    "#make dictionary mapping by converting each word to unique ids.\n",
    "dictionary = Dictionary(gen_docs)\n",
    "print(dictionary.token2id)\n",
    "#ceate bag of words\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1\n"
     ]
    }
   ],
   "source": [
    "file2_docs = []\n",
    "with open (text_doc) as f:\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    for line in tokens:\n",
    "        file2_docs.append(line)\n",
    "\n",
    "print(\"Number of sentences:\",len(file2_docs))  \n",
    "for line in file2_docs:\n",
    "    query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term frequency is how often the word shows up in the document and inverse document frequency scales the value by how rare the word is in the corpus. In simple terms, words that occur more frequently across the documents get smaller weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating similarity measure object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # create index for main doc corpus and store matrix in wokrdir\n",
    "sims = gensim.similarities.Similarity('workdir/',tf_idf[corpus],\n",
    "                                        num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document similarities to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Result: [0.88040876 0.10259783]\n"
     ]
    }
   ],
   "source": [
    "# perform a similarity query against the corpus\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "# print(document_number, document_similarity)\n",
    "print('Comparing Result:', sims[query_doc_tf_idf]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9830066\n"
     ]
    }
   ],
   "source": [
    "sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "print(sum_of_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity float: 0.4915032982826233\n",
      "Average similarity percentage: 49.15032982826233\n",
      "Average similarity rounded percentage: 49\n"
     ]
    }
   ],
   "source": [
    "percentage_of_similarity = round(float((sum_of_sims / len(file_docs)) * 100))\n",
    "print(f'Average similarity float: {float(sum_of_sims / len(file_docs))}')\n",
    "print(f'Average similarity percentage: {float(sum_of_sims / len(file_docs)) * 100}')\n",
    "print(f'Average similarity rounded percentage: {percentage_of_similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg: 0.4915032982826233\n"
     ]
    }
   ],
   "source": [
    "avg_sims = [] # array of averages\n",
    "\n",
    "# calculate average of similarity for each query doc\n",
    "avg = sum_of_sims / len(file_docs)\n",
    "# print average of similarity for each query doc\n",
    "print(f'avg: {sum_of_sims / len(file_docs)}')\n",
    "# add average values into array\n",
    "avg_sims.append(avg)  \n",
    "# calculate total average\n",
    "total_avg = ((np.sum(avg_sims, dtype=np.float)) / len(file2_docs))\n",
    "# round the value and multiply by 100 to format it as percentage\n",
    "percentage_of_similarity = round(float(total_avg) * 100)\n",
    "# if percentage is greater than 100\n",
    "# that means documents are almost same\n",
    "if percentage_of_similarity >= 100:\n",
    "    percentage_of_similarity = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49%\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "percentage = \"{:.0%}\".format((sum_of_sims / len(file_docs)))\n",
    "print(percentage)\n",
    "value = sum_of_sims / len(file_docs) * 100\n",
    "score = int(value)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getgrade(score):\n",
    "    if (score >= 90.0):\n",
    "        return 'A'\n",
    "    if(score >= 70.0 and score <= 80.0):\n",
    "        return 'B'\n",
    "    if(score >= 50.0 and score <= 60.0):\n",
    "        return 'C'\n",
    "    if(score >= 40.0):\n",
    "        return 'D'\n",
    "    if(score <= 30.0):\n",
    "        return 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canquest(s):\n",
    "    str = \" \"\n",
    "    return (str.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course title: ecn314 \n",
      "\n",
      "Question: ['What is econometrics'] \n",
      "\n",
      "Candidate answer: econometrics is the branch of economics concerned with the use of mathematical methods (especially statistics) using ecnomomics principles.\n",
      "Correct answers: the branch of economics concerned with the use of mathematical methods (especially statistics) in describing economic systems. Econometrics sutudies how mathematics relates with economics\n",
      "Similarity to answer(percentage): 49%\n",
      "Similarity to answer: D\n"
     ]
    }
   ],
   "source": [
    "print('Course title:',course,'\\n')\n",
    "print('Question:',question,'\\n',)\n",
    "print('Candidate answer:', canquest(file2_docs))\n",
    "print('Correct answers:', canquest(file_docs))\n",
    "print('Similarity to answer(percentage):', percentage)\n",
    "print('Similarity to answer:', getgrade(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
